{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "sys.path.append(Path.cwd() / \"indra_stmt_classifier_model\")\n",
    "\n",
    "from indra_stmt_classifier_model import indra_stmt_classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_annotated_sample_data = []\n",
    "with open(Path.cwd() / 'data' / 'indra_benchmark_corpus_annotated_sample.jsonl', 'r') as f:\n",
    "    for line in f:\n",
    "        random_annotated_sample_data.append(json.loads(line))\n",
    "random_annotated_sample_data = random_annotated_sample_data[:100]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model_path = Path.cwd() / 'output' / 'indra_stmt_classifier' / 'checkpoint-790'\n",
    "classifier = indra_stmt_classifier.IndraStmtClassifier(classifier_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting labels: 100%|██████████| 100/100 [00:17<00:00,  5.70it/s]\n"
     ]
    }
   ],
   "source": [
    "actual_labels = [data['statement']['type'] for data in random_annotated_sample_data]\n",
    "predicted_labels = []\n",
    "for data in tqdm(random_annotated_sample_data, desc=\"Predicting labels\", total=len(random_annotated_sample_data)):\n",
    "    predicted_labels.append(classifier.predict(data['text'])['predicted_label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = sum([1 for actual, predicted in zip(actual_labels, predicted_labels) if actual == predicted]) / len(actual_labels)\n",
    "accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predicted_label': 'IncreaseAmount',\n",
       " 'confidence': 0.47127407789230347,\n",
       " 'probabilities': {'Acetylation': 0.006579377688467503,\n",
       "  'Activation': 0.3926742970943451,\n",
       "  'Complex': 0.049027130007743835,\n",
       "  'Deacetylation': 0.009745579212903976,\n",
       "  'DecreaseAmount': 0.011002132669091225,\n",
       "  'Demethylation': 0.010597997345030308,\n",
       "  'Dephosphorylation': 0.0023687861394137144,\n",
       "  'Desumoylation': 0.003114895662292838,\n",
       "  'Deubiquitination': 0.0021336455829441547,\n",
       "  'Glycosylation': 0.005952021572738886,\n",
       "  'Hydroxylation': 0.003951319493353367,\n",
       "  'IncreaseAmount': 0.47127407789230347,\n",
       "  'Inhibition': 0.006291397847235203,\n",
       "  'Methylation': 0.007436672691255808,\n",
       "  'Phosphorylation': 0.0026918970979750156,\n",
       "  'Sumoylation': 0.0030380042735487223,\n",
       "  'Translocation': 0.004635949619114399,\n",
       "  'Ubiquitination': 0.00748478015884757},\n",
       " 'input_ids': tensor([[   2,   65, 2029,   42, 9098, 1701, 2461, 2181, 1685,   66,    3,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0]]),\n",
       " 'decoded_text': '[CLS] x has a tendency to increase expression of y [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict(\"X has a tendency to increase expression of Y\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomaslim/miniconda3/envs/indra_gpt/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from indra_stmt_agents_ner_model.preprocess import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing: 2000it [00:00, 154004.19it/s]\n",
      "Map: 100%|██████████| 2000/2000 [00:01<00:00, 1669.85 examples/s]\n"
     ]
    }
   ],
   "source": [
    "input_path = Path.cwd() / 'data' / 'indra_benchmark_corpus_annotated_sample.jsonl'\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\")\n",
    "examples = load_and_preprocess_from_raw_data(input_path)\n",
    "label2id, id2label = build_label_mappings(examples, tokenizer)\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "hf_dataset = Dataset.from_list(examples)\n",
    "processed_dataset = hf_dataset.map(\n",
    "    lambda x: preprocess_examples_from_dataset(x, tokenizer, label2id),\n",
    "    batched=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from indra_stmt_agents_ner_model import indra_stmt_agents_tagger\n",
    "\n",
    "classifier_model_path = Path.cwd() / 'output' / 'indra_stmt_agents_ner' / 'checkpoint-79'\n",
    "\n",
    "tagger = indra_stmt_agents_tagger.IndraAgentsTagger(classifier_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'annotated_text': '<agent>X </agent><agent>has </agent><agent>a </agent><agent>tendency </agent><agent>to </agent><agent>activate </agent><agent>Y</agent>',\n",
       " 'tokens': ['[CLS]',\n",
       "  'activation',\n",
       "  '[SEP]',\n",
       "  'x',\n",
       "  'has',\n",
       "  'a',\n",
       "  'tendency',\n",
       "  'to',\n",
       "  'activate',\n",
       "  'y',\n",
       "  '[SEP]'],\n",
       " 'bio_tags': ['B-agent',\n",
       "  'B-agent',\n",
       "  'B-agent',\n",
       "  'B-agent',\n",
       "  'B-agent',\n",
       "  'B-agent',\n",
       "  'B-agent',\n",
       "  'B-agent',\n",
       "  'B-agent',\n",
       "  'B-agent',\n",
       "  'B-agent']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger.predict(\"Activation\", \"X has a tendency to activate Y\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing: 1800it [00:00, 211934.63it/s]\n",
      "Map: 100%|██████████| 1260/1260 [00:00<00:00, 1890.65 examples/s]\n",
      "Map: 100%|██████████| 360/360 [00:00<00:00, 1989.08 examples/s]\n",
      "Map: 100%|██████████| 180/180 [00:00<00:00, 1964.11 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from indra_stmt_agents_ner_model.preprocess import load_and_preprocess_from_raw_data, build_label_mappings, preprocess_examples_from_dataset\n",
    "from datasets import Dataset\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\")\n",
    "\n",
    "# ---- Load raw data ----\n",
    "raw_examples = load_and_preprocess_from_raw_data(Path.cwd() / \"data\" /\"indra_benchmark_corpus_annotated_stratified_sample.jsonl\")\n",
    "\n",
    "# ---- Build label mappings from dataset ----\n",
    "label2id, id2label = build_label_mappings(raw_examples, tokenizer)\n",
    "\n",
    "# ---- Convert to HuggingFace Dataset ----\n",
    "dataset = Dataset.from_list(raw_examples)\n",
    "\n",
    "# ---- Split dataset ----\n",
    "split_dataset = dataset.train_test_split(test_size=0.3, seed=42)\n",
    "train_dataset = split_dataset[\"train\"]\n",
    "temp_dataset = split_dataset[\"test\"]\n",
    "val_test_split = temp_dataset.train_test_split(test_size=1/3, seed=42)\n",
    "val_dataset = val_test_split[\"train\"]\n",
    "test_dataset = val_test_split[\"test\"]\n",
    "\n",
    "# ---- Preprocess for model ----\n",
    "train_dataset = train_dataset.map(\n",
    "    lambda x: preprocess_examples_from_dataset(x, tokenizer, label2id),\n",
    "    batched=True\n",
    ")\n",
    "val_dataset = val_dataset.map(\n",
    "    lambda x: preprocess_examples_from_dataset(x, tokenizer, label2id),\n",
    "    batched=True\n",
    ")\n",
    "test_dataset = test_dataset.map(\n",
    "    lambda x: preprocess_examples_from_dataset(x, tokenizer, label2id),\n",
    "    batched=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-agent': 0,\n",
       " 'B-enz': 1,\n",
       " 'B-members': 2,\n",
       " 'B-obj': 3,\n",
       " 'B-sub': 4,\n",
       " 'B-subj': 5,\n",
       " 'I-agent': 6,\n",
       " 'I-enz': 7,\n",
       " 'I-members': 8,\n",
       " 'I-obj': 9,\n",
       " 'I-sub': 10,\n",
       " 'I-subj': 11,\n",
       " 'O': 12}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['matches_hash', 'statement_type', 'annotated_text', 'input_ids', 'attention_mask', 'labels', 'tokens', 'ner_tags'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0].keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Moreover, modulation of DAX-1 and steroidogenic factor-1 intracellular levels in these cells suggests that these transcription factors could be involved in <subj>MAPK</subj> suppression of <obj>StAR</obj> expression.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]['annotated_text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]: O\n",
      "inhibition: O\n",
      "[SEP]: O\n",
      "moreover: O\n",
      ",: O\n",
      "modulation: O\n",
      "of: O\n",
      "da: O\n",
      "##x: O\n",
      "-: O\n",
      "1: O\n",
      "and: O\n",
      "steroidogenic: O\n",
      "factor: O\n",
      "-: O\n",
      "1: O\n",
      "intracellular: O\n",
      "levels: O\n",
      "in: O\n",
      "these: O\n",
      "cells: O\n",
      "suggests: O\n",
      "that: O\n",
      "these: O\n",
      "transcription: O\n",
      "factors: O\n",
      "could: O\n",
      "be: O\n",
      "involved: O\n",
      "in: O\n",
      "mapk: B-subj\n",
      "suppression: O\n",
      "of: O\n",
      "star: B-obj\n",
      "expression: O\n",
      ".: O\n",
      "[SEP]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n",
      "[PAD]: O\n"
     ]
    }
   ],
   "source": [
    "for token, label in zip(train_dataset[0]['tokens'], train_dataset[0]['labels']):\n",
    "    print(f\"{token}: {id2label[label]}\")  # Print token and its corresponding label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({12: 639380, 7: 1058, 10: 904, 1: 867, 4: 811, 9: 543, 11: 486, 5: 278, 3: 272, 8: 229, 2: 142, 0: 75, 6: 75})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "all_labels = [l for example in train_dataset for l in example[\"labels\"] if l != -100]\n",
    "print(Counter(all_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "indra_gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
